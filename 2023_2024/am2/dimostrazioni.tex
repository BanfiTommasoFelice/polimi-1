\documentclass[12pt, a4paper]{article}

\usepackage[margin=2cm]{geometry}
\usepackage{ragged2e}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{hyperref}

\newtheorem{theorem}{Theorem}[section]

\title{Memoria}
\author{Gabr1313}
\date{\today}

\begin{document}
\justify
\sloppy
\maketitle
% \tableofcontents

\newpage
\begin{theorem} [Formula risolutiva per le EDO del primo ordine lineari]
	Date $a, b: I \subseteq \mathbb{R} \rightarrow \mathbb{R}$ continue,
	l'integrale generale delle EDO
	\[
		y'(t) = a(t) y(t) + b(t)
	\]
	con $t \in I $, è dato da:
	\[
		y(t) = e^A \left( \int e^{-A} b(t) dt + c \right)
	\]
	dove $A = \int a(t) dt$, $t \in I$, $c \in \mathbb{R}$.
\end{theorem}
\begin{proof}
	\begin{itemize}
		\item
			\begin{align*}
				(y e^{-A})' & = y' e^{-A} + [ye^{-A}(-a')] \\
				            & = y' e^{-A} - aye^{-A}       \\
				            & = (y' - ay)e^{-A}            \\
				            & = (b)e^{-A}
			\end{align*}
		\item Utilizzando il teorema fondamentale del calcolo integrale
			\begin{align*}
				y e^{-A} & = \int (y e^{-A})' dt       \\
				         & = \int (b)e^{-A} dt + c     \\
				y        & = e^A \int (b)e^{-A} dt + c \\
			\end{align*}
			dove $c \in \mathbb{R}$.
	\end{itemize}
\end{proof}

\newpage
\begin{theorem} [Teorema di struttura dell’integrale generale di equazioni del
	secondo ordine lineari omogenee]
	Siano $a, b, c: I \subseteq \mathbb{R} \rightarrow \mathbb{R}$ continue, $a
		\neq 0$, allora la EDO
	\[
		a(t) y''(t) + b(t) y'(t) + c(t) y(t) = 0
	\]
	con $t \in I $ ha come IG uno spazio vettoriale di dimensione 2
	\[
		y_o(t) = c_1 y_{o,1}(t) + c_2 y_{o,2}(t)
	\]
	con $c_1, c_2 \in \mathbb{R}$, dove $y_{o,1}, y_{o,2}$ sono due soluzioni
	linearmente indipendenti dell'EDO.
\end{theorem}
\begin{proof}
	\begin{itemize}
		\item per il pricipio di Sovrapposizione l'insieme di tutte le soluzioni
			è uno spazio vettoriale, perchè chiuso rispetto alla somma e al
			prodotto per uno scalare. Rimane quindi da dimostrare che la
			dimesione di tale spazio vettoriale è 2:
			\begin{itemize}
				\item si trovano $y_{o,1}$ e $y_{o,2}$ LI
				\item si dimostra che ogni soluzione si possa scrivere come
					combinazione lineare di queste due
			\end{itemize}
		\item Si scelgono $y_{o,1}, y_{o,2}$ come soluzioni di problemi di
			Cauchy seguenti con $t_o \in I$ fissato
			\begin{align*}
				\begin{cases}
					a(t) y''(t) + b(t) y'(t) + c(t) y(t) = 0 \\
					y(t_o) = 1                               \\
					y'(t_o) = 0                              \\
				\end{cases}
			\end{align*}
			\begin{align*}
				\begin{cases}
					a(t) y''(t) + b(t) y'(t) + c(t) y(t) = 0 \\
					y(t_o) = 0                               \\
					y'(t_o) = 1                              \\
				\end{cases}
			\end{align*}
			Queste soluzioni esistono e sono uniche per il teorema di $\exists
				!$ del PC. $y_{o,1}$ e $y_{o,2}$ sono inoltre LI perchè se per
			assurdo si ipotizzasse che $\exists c \neq 0 : y_{o,1} = c y_{o,2}
				\forall t \in I$, allora $1 = y_{o,1}(t_o) = c y_{o,2}(t_o) =
				0$.
		\item Sia $\bar{y}_o$ una qualunque soluzione particolare della EDO, si
			cercano $c_1, c_2 \in \mathbb{R}$ in modo tale che
			$\bar{y}_o(t)$ coincida con
			\[
				z(t) = c_1 y_{o,1}(t) + c_2 y_{o,2}(t)
			\]
			la quale è una soluzione per il Principio di Sovrapposizione.\\
			Si scelgono quindi $c_1, c_2$ in modo che:
			\begin{align*}
				\bar{y}_o(t_o) = z(t_o) = c_1 y_{o,1}(t_o) + c_2 y_{o,2}(t_o) =
				c_1         \\
				\bar{y}'_o(t_o) = z'(t_o) = c_1 y'_{o,1}(t_o) + c_2 y'_{o,2}
				(t_o) = c_2 \\
			\end{align*}
			quindi
			\begin{align*}
				z(t) = \bar{y}_o(t_o) y_{o,1}(t) + \bar{y}'_o(t_o) y_{o,2}(t)
			\end{align*}
			Sia $\bar{y}_o$ che $z$ soddisfano lo stesso PC
			\begin{align*}
				\begin{cases}
					a(t) y''(t) + b(t) y'(t) + c(t) y(t) = 0 \\
					y(t_o) = y_o(t_o)                        \\
					y'(t_o) = y_o'(t_o)                      \\
				\end{cases}
			\end{align*}
			e quindi per il teorema di $\exists !$ del PC $\bar{y}_o(t) = z(t)$.
	\end{itemize}
\end{proof}

\newpage
\begin{theorem} [Criterio della radice e criterio del rapporto per la
	determinazione del raggio di convergenza]
	Data la serie
	\[
		\sum_{n=0}^{\infty} a_n (x - x_o)^n
	\]
	con $a_n \in
		\mathbb{R}$, se:
	\begin{align*}
		\exists R & = \lim_{n \rightarrow \infty} \left| \frac{a_n}{a_{n+1}}
		\right| \text{ oppure }                                                  \\
		\exists R & = \lim_{n \rightarrow \infty} \left| \frac{1}{\sqrt[n]{a_n}}
		\right|
	\end{align*}
	con $R \in [0,+\infty]$, allora la serie converge e ha raggio $R$.
\end{theorem}
\begin{proof}
	\begin{itemize}
		\item Per il teorema del raggio di convergenza di una serie di potenze
			e' sufficiente verificare che:
			\[
				\sum_{n=0}^{\infty} \left| a_n (x - x_o)^n \right|
			\]
			\begin{itemize}
				\item converge per $|x - x_o| < R$
				\item non converge per $|x - x_o| > R$
			\end{itemize}
		\item tutte le serie convergono per $x = x_o$; nel caso in cui $x \neq
			x_o$ si puo' applicare il criterio del rapporto alla serie di
			partenza:
			\[
				\lim_{n \rightarrow \infty} \left| \frac{a_{n+1}(x-x_0)^{n+1}}
				{a_n (x-x_0)^n} \right| = \left| x - x_0 \right| \lim_{n
				\rightarrow \infty} \left| \frac{a_{n+1}}{a_n} \right| =
				\frac{\left| x -
				x_0 \right|}{R}
			\]
			E quindi i 2 punti precedenti sono verificati.
		\item $\forall x \in \mathbb{R} $ si puo' applicare il criterio della
			radice alla serie di partenza:
			\[
				\lim_{n \rightarrow \infty} \sqrt[n]{\left| a_n (x-x_0)^n
				\right|} = \lim_{n \rightarrow \infty} \left| x - x_0 \right|
				\sqrt[n]{\left| a_n \right|} = \frac{\left| x - x_0 \right|}{R}
			\]
			E quindi i 2 punti precedenti sono verificati.
	\end{itemize}
\end{proof}

\newpage
\begin{theorem} [Calcolo dei coefficienti di Fourier di una funzione periodica]
\end{theorem}
\begin{proof}
\end{proof}

\newpage
\begin{theorem} [Invarianza della lunghezza per riparametrizzazioni]
\end{theorem}
\begin{proof}
\end{proof}

\newpage
\begin{theorem} [Differenziabilità implica continuità]
\end{theorem}
\begin{proof}
\end{proof}

\newpage
\begin{theorem} [Formula del gradiente]
\end{theorem}
\begin{proof}
\end{proof}

\newpage
\begin{theorem} [Ortogonalità del gradiente agli insiemi di livello]
\end{theorem}
\begin{proof}
\end{proof}

\newpage
\begin{theorem} [Criterio della matrice Hessiana]
\end{theorem}
\begin{proof}
\end{proof}

\newpage
\begin{theorem} [Cambiamenti di variabili in coordinate polari, cilindriche, e
	sferiche e loro Jacobiano]
\end{theorem}
\begin{proof}
\end{proof}

\end{document}
